[2024-03-14T10:46:43.875+0000] {processor.py:161} INFO - Started process (PID=47) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:46:43.880+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:46:43.882+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:46:43.882+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:46:44.048+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:46:44.074+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:46:44.074+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:46:44.157+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:46:44.148+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:46:44.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.369 seconds
[2024-03-14T10:47:14.747+0000] {processor.py:161} INFO - Started process (PID=101) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:47:14.761+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:47:14.766+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:47:14.766+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:47:14.824+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:47:15.150+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:47:15.150+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:47:15.186+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:47:15.186+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:47:15.224+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.480 seconds
[2024-03-14T10:47:45.343+0000] {processor.py:161} INFO - Started process (PID=156) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:47:45.344+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:47:45.353+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:47:45.353+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:47:45.416+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:47:45.494+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:47:45.493+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:47:45.549+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:47:45.549+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:47:45.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.255 seconds
[2024-03-14T10:48:16.458+0000] {processor.py:161} INFO - Started process (PID=211) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:48:16.459+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:48:16.461+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:48:16.460+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:48:16.494+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:48:16.520+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:48:16.519+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:48:16.541+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:48:16.541+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:48:16.562+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.106 seconds
[2024-03-14T10:48:47.298+0000] {processor.py:161} INFO - Started process (PID=266) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:48:47.299+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:48:47.301+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:48:47.300+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:48:47.329+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:48:47.353+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:48:47.352+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:48:47.376+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:48:47.376+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:48:47.394+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.099 seconds
[2024-03-14T10:49:18.096+0000] {processor.py:161} INFO - Started process (PID=321) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:49:18.097+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:49:18.099+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:49:18.098+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:49:18.126+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:49:18.152+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:49:18.152+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:49:18.175+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:49:18.174+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:49:18.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.102 seconds
[2024-03-14T10:49:48.799+0000] {processor.py:161} INFO - Started process (PID=376) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:49:48.800+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:49:48.802+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:49:48.801+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:49:48.836+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:49:48.862+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:49:48.862+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:49:48.884+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:49:48.884+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:49:48.902+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.106 seconds
[2024-03-14T10:50:19.798+0000] {processor.py:161} INFO - Started process (PID=431) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:50:19.799+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:50:19.802+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:50:19.801+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:50:19.837+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:50:19.863+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:50:19.863+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:50:19.887+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:50:19.887+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:50:19.910+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.114 seconds
[2024-03-14T10:50:49.993+0000] {processor.py:161} INFO - Started process (PID=486) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:50:49.995+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:50:49.997+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:50:49.997+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:50:50.024+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:50:50.052+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:50:50.051+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:50:50.073+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:50:50.073+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:50:50.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.101 seconds
[2024-03-14T10:51:20.825+0000] {processor.py:161} INFO - Started process (PID=541) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:51:20.826+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:51:20.832+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:51:20.832+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:51:20.864+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:51:20.888+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:51:20.887+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:51:20.909+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:51:20.909+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:51:20.930+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.108 seconds
[2024-03-14T10:51:51.583+0000] {processor.py:161} INFO - Started process (PID=596) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:51:51.584+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:51:51.597+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:51:51.596+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:51:51.624+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:51:51.647+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:51:51.646+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:51:51.669+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:51:51.669+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:51:51.687+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.107 seconds
[2024-03-14T10:52:22.494+0000] {processor.py:161} INFO - Started process (PID=651) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:52:22.495+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:52:22.498+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:52:22.498+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:52:22.528+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:52:22.553+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:52:22.553+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:52:22.576+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:52:22.576+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:52:22.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.107 seconds
[2024-03-14T10:52:53.577+0000] {processor.py:161} INFO - Started process (PID=707) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:52:53.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:52:53.580+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:52:53.580+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:52:53.608+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:52:53.632+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:52:53.632+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:52:53.657+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:52:53.657+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:52:53.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.100 seconds
[2024-03-14T10:53:23.802+0000] {processor.py:161} INFO - Started process (PID=762) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:53:23.806+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:53:23.813+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:53:23.813+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:53:23.890+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:53:23.926+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:53:23.925+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:53:23.980+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:53:23.980+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:53:24.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.241 seconds
[2024-03-14T10:53:54.491+0000] {processor.py:161} INFO - Started process (PID=817) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:53:54.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:53:54.495+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:53:54.494+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:53:54.524+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:53:54.549+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:53:54.549+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:53:54.571+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:53:54.571+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:53:54.594+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.106 seconds
[2024-03-14T10:54:24.864+0000] {processor.py:161} INFO - Started process (PID=872) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:54:24.865+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:54:24.867+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:54:24.866+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:54:24.893+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:54:24.922+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:54:24.922+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:54:24.945+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:54:24.945+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:54:24.964+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.103 seconds
[2024-03-14T10:54:55.880+0000] {processor.py:161} INFO - Started process (PID=927) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:54:55.881+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:54:55.883+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:54:55.883+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:54:55.932+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:54:55.969+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:54:55.969+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:54:55.997+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:54:55.996+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:54:56.017+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.141 seconds
[2024-03-14T10:55:26.749+0000] {processor.py:161} INFO - Started process (PID=982) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:55:26.750+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:55:26.752+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:55:26.752+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:55:26.791+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:55:26.815+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:55:26.815+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:55:26.838+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:55:26.838+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:55:26.856+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.110 seconds
[2024-03-14T10:55:57.106+0000] {processor.py:161} INFO - Started process (PID=1036) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:55:57.108+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:55:57.111+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:55:57.110+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:55:57.180+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:55:57.210+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:55:57.210+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:55:57.254+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:55:57.253+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:55:57.284+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.183 seconds
[2024-03-14T10:56:27.359+0000] {processor.py:161} INFO - Started process (PID=1091) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:56:27.364+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:56:27.371+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:56:27.371+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:56:27.485+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:56:27.541+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:56:27.540+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:56:27.584+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:56:27.583+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:56:27.604+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.250 seconds
[2024-03-14T10:56:58.253+0000] {processor.py:161} INFO - Started process (PID=1146) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:56:58.254+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:56:58.255+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:56:58.255+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:56:58.294+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:56:58.325+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:56:58.325+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:56:58.349+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:56:58.348+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:56:58.382+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.132 seconds
[2024-03-14T10:57:28.437+0000] {processor.py:161} INFO - Started process (PID=1200) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:57:28.438+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:57:28.440+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:57:28.440+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:57:28.484+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:57:28.535+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:57:28.534+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:57:28.569+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:57:28.569+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:57:28.601+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.168 seconds
[2024-03-14T10:57:59.244+0000] {processor.py:161} INFO - Started process (PID=1255) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:57:59.245+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:57:59.248+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:57:59.247+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:57:59.299+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:57:59.506+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:57:59.506+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:57:59.536+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:57:59.536+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:57:59.571+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.331 seconds
[2024-03-14T10:58:03.544+0000] {processor.py:161} INFO - Started process (PID=1278) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:58:03.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:58:03.550+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:58:03.549+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:58:03.570+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:58:03.566+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 89
    format_to_parquet_task >> bridge2
    ^
IndentationError: unexpected indent
[2024-03-14T10:58:03.571+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:58:03.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.059 seconds
[2024-03-14T10:58:06.681+0000] {processor.py:161} INFO - Started process (PID=1293) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:58:06.682+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:58:06.685+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:58:06.684+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:58:06.743+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:58:06.762+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:58:06.762+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:58:06.791+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:58:06.791+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:58:06.824+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.147 seconds
[2024-03-14T10:58:37.088+0000] {processor.py:161} INFO - Started process (PID=1348) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:58:37.091+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:58:37.096+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:58:37.095+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:58:37.145+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:58:37.290+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:58:37.289+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:58:37.316+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:58:37.316+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:58:37.340+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.255 seconds
[2024-03-14T10:58:37.409+0000] {processor.py:161} INFO - Started process (PID=1352) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:58:37.410+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:58:37.419+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:58:37.417+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:58:37.474+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:58:37.470+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 78, in <module>
    start >> download_task >> format_to_parquet_task
NameError: name 'format_to_parquet_task' is not defined
[2024-03-14T10:58:37.475+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:58:37.515+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.110 seconds
[2024-03-14T10:59:07.729+0000] {processor.py:161} INFO - Started process (PID=1405) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:59:07.731+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:59:07.734+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:59:07.733+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:59:07.825+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:59:07.807+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 78, in <module>
    start >> download_task >> format_to_parquet_task
NameError: name 'format_to_parquet_task' is not defined
[2024-03-14T10:59:07.829+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:59:07.861+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.136 seconds
[2024-03-14T10:59:38.482+0000] {processor.py:161} INFO - Started process (PID=1460) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:59:38.483+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:59:38.486+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:59:38.485+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:59:38.519+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:59:38.513+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 78, in <module>
    start >> download_task >> format_to_parquet_task
NameError: name 'format_to_parquet_task' is not defined
[2024-03-14T10:59:38.520+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:59:38.536+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.057 seconds
[2024-03-14T10:59:38.846+0000] {processor.py:161} INFO - Started process (PID=1465) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:59:38.848+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:59:38.850+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:59:38.850+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:59:38.905+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:59:39.047+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:59:39.047+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:59:39.075+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:59:39.075+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:59:39.111+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.270 seconds
[2024-03-14T10:59:42.815+0000] {processor.py:161} INFO - Started process (PID=1479) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T10:59:42.816+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T10:59:42.818+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:59:42.817+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T10:59:42.851+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T10:59:42.861+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:59:42.861+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T10:59:42.884+0000] {logging_mixin.py:188} INFO - [2024-03-14T10:59:42.884+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T10:59:42.905+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.092 seconds
[2024-03-14T11:00:13.400+0000] {processor.py:161} INFO - Started process (PID=1534) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:00:13.401+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:00:13.403+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:00:13.402+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:00:13.434+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:00:13.538+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:00:13.538+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:00:13.561+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:00:13.561+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:00:13.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.188 seconds
[2024-03-14T11:00:44.023+0000] {processor.py:161} INFO - Started process (PID=1590) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:00:44.025+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:00:44.028+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:00:44.028+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:00:44.065+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:00:44.095+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:00:44.095+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:00:44.122+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:00:44.122+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:00:44.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.127 seconds
[2024-03-14T11:01:14.303+0000] {processor.py:161} INFO - Started process (PID=1644) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:01:14.304+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:01:14.307+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:01:14.307+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:01:14.344+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:01:14.370+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:01:14.369+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:01:14.392+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:01:14.392+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:01:14.418+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.118 seconds
[2024-03-14T11:01:22.436+0000] {processor.py:161} INFO - Started process (PID=1645) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:01:22.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:01:22.440+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:01:22.439+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:01:22.488+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:01:22.610+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:01:22.610+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:01:22.635+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:01:22.635+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:01:22.665+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.234 seconds
[2024-03-14T11:01:36.454+0000] {processor.py:161} INFO - Started process (PID=1665) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:01:36.455+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:01:36.457+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:01:36.456+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:01:36.494+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:01:36.505+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:01:36.505+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:01:36.535+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:01:36.535+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:01:36.567+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.116 seconds
[2024-03-14T11:02:06.909+0000] {processor.py:161} INFO - Started process (PID=1721) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:02:06.929+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:02:06.939+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:02:06.939+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:02:07.138+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:02:07.503+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:02:07.502+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:02:07.549+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:02:07.549+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:02:07.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.726 seconds
[2024-03-14T11:02:38.543+0000] {processor.py:161} INFO - Started process (PID=1777) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:02:38.544+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:02:38.547+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:02:38.547+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:02:38.585+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:02:38.617+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:02:38.616+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:02:38.651+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:02:38.651+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:02:38.677+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.139 seconds
[2024-03-14T11:03:09.089+0000] {processor.py:161} INFO - Started process (PID=1832) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:03:09.090+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:03:09.093+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:03:09.092+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:03:09.121+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:03:09.151+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:03:09.151+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:03:09.175+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:03:09.174+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:03:09.201+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.116 seconds
[2024-03-14T11:03:39.538+0000] {processor.py:161} INFO - Started process (PID=1887) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:03:39.539+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:03:39.542+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:03:39.541+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:03:39.582+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:03:39.612+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:03:39.612+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:03:39.634+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:03:39.633+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:03:39.653+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.118 seconds
[2024-03-14T11:04:10.032+0000] {processor.py:161} INFO - Started process (PID=1942) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:04:10.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:04:10.036+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:04:10.036+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:04:10.097+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:04:10.123+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:04:10.123+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:04:10.153+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:04:10.152+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:04:10.175+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.155 seconds
[2024-03-14T11:04:40.612+0000] {processor.py:161} INFO - Started process (PID=1997) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:04:40.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:04:40.616+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:04:40.615+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:04:40.654+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:04:40.679+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:04:40.679+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:04:40.709+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:04:40.709+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:04:40.738+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.128 seconds
[2024-03-14T11:05:10.943+0000] {processor.py:161} INFO - Started process (PID=2052) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:05:10.944+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:05:10.947+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:05:10.947+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:05:10.982+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:05:11.015+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:05:11.015+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:05:11.039+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:05:11.038+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:05:11.057+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.117 seconds
[2024-03-14T11:05:41.454+0000] {processor.py:161} INFO - Started process (PID=2107) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:05:41.455+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:05:41.458+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:05:41.457+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:05:41.493+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:05:41.514+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:05:41.514+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:05:41.536+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:05:41.536+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:05:41.556+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.105 seconds
[2024-03-14T11:06:11.622+0000] {processor.py:161} INFO - Started process (PID=2161) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:06:11.623+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:06:11.626+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:06:11.625+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:06:11.656+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:06:11.685+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:06:11.685+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:06:11.714+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:06:11.714+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:06:11.744+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.124 seconds
[2024-03-14T11:06:42.119+0000] {processor.py:161} INFO - Started process (PID=2216) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:06:42.120+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:06:42.122+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:06:42.122+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:06:42.149+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:06:42.175+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:06:42.175+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:06:42.198+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:06:42.197+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:06:42.223+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.107 seconds
[2024-03-14T11:07:12.718+0000] {processor.py:161} INFO - Started process (PID=2271) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:07:12.720+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:07:12.723+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:07:12.722+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:07:12.760+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:07:12.794+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:07:12.794+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:07:12.825+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:07:12.825+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:07:12.849+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.134 seconds
[2024-03-14T11:07:31.410+0000] {processor.py:161} INFO - Started process (PID=2306) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:07:31.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:07:31.413+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:07:31.412+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:07:31.447+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:07:31.470+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:07:31.470+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:07:31.495+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:07:31.494+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:07:31.530+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.122 seconds
[2024-03-14T11:08:01.611+0000] {processor.py:161} INFO - Started process (PID=2361) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:08:01.612+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:08:01.614+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:08:01.614+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:08:01.659+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:08:01.703+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:08:01.702+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:08:01.745+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:08:01.745+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:08:01.774+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.168 seconds
[2024-03-14T11:08:31.920+0000] {processor.py:161} INFO - Started process (PID=2421) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:08:31.921+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:08:31.922+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:08:31.922+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:08:31.948+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:08:31.970+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:08:31.969+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:08:31.992+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:08:31.991+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:08:32.009+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.092 seconds
[2024-03-14T11:09:02.373+0000] {processor.py:161} INFO - Started process (PID=2476) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:09:02.375+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:09:02.377+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:09:02.377+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:09:02.406+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:09:02.429+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:09:02.429+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:09:02.455+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:09:02.455+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:09:02.486+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.115 seconds
[2024-03-14T11:09:32.651+0000] {processor.py:161} INFO - Started process (PID=2531) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:09:32.652+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:09:32.655+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:09:32.654+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:09:32.715+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:09:32.776+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:09:32.775+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:09:32.813+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:09:32.813+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:09:32.853+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.205 seconds
[2024-03-14T11:10:03.138+0000] {processor.py:161} INFO - Started process (PID=2586) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:10:03.142+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:10:03.145+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:10:03.144+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:10:03.186+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:10:03.219+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:10:03.219+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:10:03.248+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:10:03.248+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:10:03.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.131 seconds
[2024-03-14T11:10:12.345+0000] {processor.py:161} INFO - Started process (PID=2588) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:10:12.346+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:10:12.348+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:10:12.347+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:10:12.404+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:10:12.551+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:10:12.551+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:10:12.614+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:10:12.614+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:10:12.646+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.304 seconds
[2024-03-14T11:10:29.435+0000] {processor.py:161} INFO - Started process (PID=2636) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:10:29.436+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:10:29.441+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:10:29.441+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:10:29.513+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:10:29.524+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:10:29.524+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:10:29.549+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:10:29.549+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:10:29.578+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.146 seconds
[2024-03-14T11:10:59.861+0000] {processor.py:161} INFO - Started process (PID=2691) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:10:59.862+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:10:59.864+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:10:59.863+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:10:59.909+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:11:00.030+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:11:00.029+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:11:00.052+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:11:00.052+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:11:00.077+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.219 seconds
[2024-03-14T11:11:30.673+0000] {processor.py:161} INFO - Started process (PID=2746) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:11:30.677+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:11:30.679+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:11:30.678+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:11:30.744+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:11:30.824+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:11:30.824+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:11:30.918+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:11:30.918+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:11:30.959+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.292 seconds
[2024-03-14T11:12:05.312+0000] {processor.py:161} INFO - Started process (PID=2807) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:12:05.316+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:12:05.352+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:12:05.350+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:12:05.723+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:12:05.857+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:12:05.856+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:12:06.028+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:12:06.024+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:12:06.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 1.060 seconds
[2024-03-14T11:12:37.252+0000] {processor.py:161} INFO - Started process (PID=2862) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:12:37.257+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:12:37.261+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:12:37.260+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:12:37.358+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:12:37.483+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:12:37.482+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:12:37.533+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:12:37.533+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:12:37.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.350 seconds
[2024-03-14T11:13:08.487+0000] {processor.py:161} INFO - Started process (PID=2917) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:13:08.498+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:13:08.500+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:13:08.500+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:13:08.600+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:13:08.662+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:13:08.662+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:13:08.726+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:13:08.726+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:13:08.770+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.289 seconds
[2024-03-14T11:13:38.970+0000] {processor.py:161} INFO - Started process (PID=2972) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:13:38.971+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:13:38.974+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:13:38.974+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:13:39.007+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:13:39.036+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:13:39.036+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:13:39.063+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:13:39.063+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:13:39.084+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.117 seconds
[2024-03-14T11:14:05.798+0000] {processor.py:161} INFO - Started process (PID=3014) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:14:05.799+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:14:05.802+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:14:05.801+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:14:05.863+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:14:06.044+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:14:06.043+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:14:06.355+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:14:06.355+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:14:06.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.607 seconds
[2024-03-14T11:14:08.366+0000] {processor.py:161} INFO - Started process (PID=3028) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:14:08.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:14:08.370+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:14:08.369+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:14:08.436+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:14:08.453+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:14:08.453+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:14:08.492+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:14:08.492+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:14:08.533+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.170 seconds
[2024-03-14T11:14:24.515+0000] {processor.py:161} INFO - Started process (PID=3041) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:14:24.517+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:14:24.525+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:14:24.523+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:14:24.622+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:14:24.642+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:14:24.641+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:14:24.691+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:14:24.690+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:14:24.752+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.246 seconds
[2024-03-14T11:14:55.160+0000] {processor.py:161} INFO - Started process (PID=3096) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:14:55.161+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:14:55.164+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:14:55.164+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:14:55.201+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:14:55.406+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:14:55.406+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:14:55.635+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:14:55.635+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:14:55.664+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.509 seconds
[2024-03-14T11:15:25.727+0000] {processor.py:161} INFO - Started process (PID=3153) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:15:25.728+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:15:25.732+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:15:25.731+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:15:25.770+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:15:25.797+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:15:25.797+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:15:25.825+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:15:25.825+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:15:25.846+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.122 seconds
[2024-03-14T11:15:56.346+0000] {processor.py:161} INFO - Started process (PID=3208) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:15:56.349+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:15:56.354+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:15:56.353+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:15:56.427+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:15:56.475+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:15:56.474+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:15:56.531+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:15:56.530+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:15:56.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.270 seconds
[2024-03-14T11:16:26.852+0000] {processor.py:161} INFO - Started process (PID=3263) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:16:26.853+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:16:26.856+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:16:26.856+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:16:26.944+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:16:27.105+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:16:27.104+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:16:27.242+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:16:27.240+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:16:27.579+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.730 seconds
[2024-03-14T11:16:58.616+0000] {processor.py:161} INFO - Started process (PID=3318) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:16:58.618+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:16:58.621+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:16:58.620+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:16:58.752+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:16:58.867+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:16:58.866+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:16:59.048+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:16:59.048+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:16:59.322+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.711 seconds
[2024-03-14T11:17:30.193+0000] {processor.py:161} INFO - Started process (PID=3374) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:17:30.194+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:17:30.200+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:17:30.199+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:17:30.243+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:17:30.310+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:17:30.309+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:17:30.367+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:17:30.367+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:17:30.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.220 seconds
[2024-03-14T11:18:01.092+0000] {processor.py:161} INFO - Started process (PID=3428) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:18:01.094+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:18:01.099+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:18:01.098+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:18:01.137+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:18:01.182+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:18:01.181+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:18:01.222+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:18:01.222+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:18:01.268+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.182 seconds
[2024-03-14T11:18:31.755+0000] {processor.py:161} INFO - Started process (PID=3484) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:18:31.756+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:18:31.758+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:18:31.758+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:18:31.794+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:18:31.818+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:18:31.818+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:18:31.851+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:18:31.850+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:18:31.883+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.131 seconds
[2024-03-14T11:19:02.594+0000] {processor.py:161} INFO - Started process (PID=3540) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:19:02.595+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:19:02.598+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:19:02.597+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:19:02.639+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:19:02.671+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:19:02.670+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:19:02.708+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:19:02.707+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:19:02.929+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.337 seconds
[2024-03-14T11:19:33.822+0000] {processor.py:161} INFO - Started process (PID=3596) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:19:33.823+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:19:33.825+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:19:33.824+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:19:33.853+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:19:33.884+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:19:33.884+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:19:33.950+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:19:33.950+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:19:33.983+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.163 seconds
[2024-03-14T11:20:04.265+0000] {processor.py:161} INFO - Started process (PID=3657) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:20:04.266+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:20:04.268+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:20:04.268+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:20:04.333+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:20:04.363+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:20:04.362+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:20:04.385+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:20:04.385+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:20:04.404+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.143 seconds
[2024-03-14T11:20:34.805+0000] {processor.py:161} INFO - Started process (PID=3712) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:20:34.807+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:20:34.811+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:20:34.811+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:20:34.860+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:20:34.902+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:20:34.902+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:20:34.941+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:20:34.941+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:20:34.976+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.175 seconds
[2024-03-14T11:21:05.138+0000] {processor.py:161} INFO - Started process (PID=3767) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:21:05.139+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:21:05.141+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:21:05.140+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:21:05.176+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:21:05.204+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:21:05.204+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:21:05.226+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:21:05.226+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:21:05.254+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.119 seconds
[2024-03-14T11:21:35.408+0000] {processor.py:161} INFO - Started process (PID=3822) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:21:35.409+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:21:35.412+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:21:35.412+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:21:35.441+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:21:35.487+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:21:35.487+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:21:35.701+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:21:35.701+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:21:35.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.327 seconds
[2024-03-14T11:22:06.023+0000] {processor.py:161} INFO - Started process (PID=3878) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:22:06.024+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:22:06.026+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:22:06.025+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:22:06.054+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:22:06.079+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:22:06.078+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:22:06.230+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:22:06.229+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:22:06.257+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.238 seconds
[2024-03-14T11:22:36.898+0000] {processor.py:161} INFO - Started process (PID=3932) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:22:36.899+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:22:36.901+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:22:36.901+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:22:36.958+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:22:37.009+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:22:37.008+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:22:37.032+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:22:37.032+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:22:37.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.178 seconds
[2024-03-14T11:23:07.593+0000] {processor.py:161} INFO - Started process (PID=3987) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:23:07.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:23:07.596+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:23:07.596+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:23:07.637+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:23:07.664+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:23:07.663+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:23:07.687+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:23:07.687+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:23:07.707+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.117 seconds
[2024-03-14T11:23:38.033+0000] {processor.py:161} INFO - Started process (PID=4043) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:23:38.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:23:38.036+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:23:38.036+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:23:38.226+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:23:38.277+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:23:38.276+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:23:38.311+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:23:38.311+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:23:38.340+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.310 seconds
[2024-03-14T11:24:08.487+0000] {processor.py:161} INFO - Started process (PID=4098) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:24:08.488+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:24:08.491+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:24:08.490+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:24:08.519+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:24:08.766+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:24:08.766+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:24:08.793+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:24:08.793+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:24:08.827+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.342 seconds
[2024-03-14T11:24:39.024+0000] {processor.py:161} INFO - Started process (PID=4153) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:24:39.025+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:24:39.028+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:24:39.027+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:24:39.061+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:24:39.091+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:24:39.091+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:24:39.125+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:24:39.124+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:24:39.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.127 seconds
[2024-03-14T11:25:09.244+0000] {processor.py:161} INFO - Started process (PID=4208) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:25:09.245+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:25:09.249+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:25:09.248+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:25:09.284+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:25:09.313+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:25:09.312+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:25:09.345+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:25:09.344+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:25:09.384+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.143 seconds
[2024-03-14T11:25:39.598+0000] {processor.py:161} INFO - Started process (PID=4263) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:25:39.600+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:25:39.603+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:25:39.602+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:25:39.642+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:25:39.678+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:25:39.677+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:25:39.707+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:25:39.706+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:25:39.733+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.138 seconds
[2024-03-14T11:26:09.808+0000] {processor.py:161} INFO - Started process (PID=4318) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:26:09.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:26:09.814+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:26:09.813+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:26:09.886+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:26:09.927+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:26:09.927+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:26:09.961+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:26:09.961+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:26:10.000+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.196 seconds
[2024-03-14T11:26:40.996+0000] {processor.py:161} INFO - Started process (PID=4373) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:26:40.997+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:26:41.000+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:26:41.000+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:26:41.041+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:26:41.069+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:26:41.069+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:26:41.097+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:26:41.097+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:26:41.115+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.121 seconds
[2024-03-14T11:27:11.219+0000] {processor.py:161} INFO - Started process (PID=4429) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:27:11.220+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:27:11.223+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:27:11.223+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:27:11.267+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:27:11.298+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:27:11.298+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:27:11.328+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:27:11.327+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:27:11.348+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.133 seconds
[2024-03-14T11:27:41.463+0000] {processor.py:161} INFO - Started process (PID=4484) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:27:41.463+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:27:41.466+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:27:41.465+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:27:41.513+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:27:41.555+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:27:41.554+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:27:41.579+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:27:41.579+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:27:41.613+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.153 seconds
[2024-03-14T11:28:11.662+0000] {processor.py:161} INFO - Started process (PID=4539) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:28:11.663+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:28:11.665+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:28:11.665+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:28:11.705+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:28:11.738+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:28:11.738+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:28:11.771+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:28:11.770+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:28:11.791+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.131 seconds
[2024-03-14T11:28:42.682+0000] {processor.py:161} INFO - Started process (PID=4594) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:28:42.684+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:28:42.686+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:28:42.686+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:28:42.716+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:28:42.741+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:28:42.740+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:28:42.770+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:28:42.770+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:28:42.789+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.110 seconds
[2024-03-14T11:29:12.905+0000] {processor.py:161} INFO - Started process (PID=4649) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:29:12.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:29:12.909+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:29:12.908+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:29:12.939+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:29:12.969+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:29:12.968+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:29:12.991+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:29:12.991+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:29:13.015+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.113 seconds
[2024-03-14T11:29:43.170+0000] {processor.py:161} INFO - Started process (PID=4704) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:29:43.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:29:43.173+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:29:43.172+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:29:43.206+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:29:43.238+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:29:43.237+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:29:43.265+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:29:43.264+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:29:43.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.119 seconds
[2024-03-14T11:30:13.402+0000] {processor.py:161} INFO - Started process (PID=4759) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:30:13.404+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:30:13.406+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:30:13.406+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:30:13.447+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:30:13.481+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:30:13.481+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:30:13.513+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:30:13.513+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:30:13.536+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.141 seconds
[2024-03-14T11:30:44.429+0000] {processor.py:161} INFO - Started process (PID=4813) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:30:44.430+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:30:44.431+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:30:44.431+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:30:44.466+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:30:44.509+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:30:44.509+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:30:44.542+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:30:44.542+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:30:44.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.143 seconds
[2024-03-14T11:31:14.808+0000] {processor.py:161} INFO - Started process (PID=4868) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:31:14.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:31:14.811+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:31:14.810+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:31:14.839+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:31:14.866+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:31:14.866+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:31:14.894+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:31:14.894+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:31:14.922+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.117 seconds
[2024-03-14T11:31:45.010+0000] {processor.py:161} INFO - Started process (PID=4923) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:31:45.012+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:31:45.014+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:31:45.014+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:31:45.046+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:31:45.084+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:31:45.084+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:31:45.121+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:31:45.121+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:31:45.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.144 seconds
[2024-03-14T11:32:15.434+0000] {processor.py:161} INFO - Started process (PID=4978) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:32:15.438+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:32:15.444+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:32:15.442+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:32:15.496+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:32:15.527+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:32:15.526+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:32:15.562+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:32:15.562+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:32:15.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.160 seconds
[2024-03-14T11:32:45.724+0000] {processor.py:161} INFO - Started process (PID=5033) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:32:45.725+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:32:45.727+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:32:45.726+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:32:45.756+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:32:45.783+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:32:45.782+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:32:45.807+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:32:45.806+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:32:45.830+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.109 seconds
[2024-03-14T11:33:16.016+0000] {processor.py:161} INFO - Started process (PID=5088) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:33:16.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:33:16.019+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:33:16.019+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:33:16.048+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:33:16.073+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:33:16.072+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:33:16.099+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:33:16.099+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:33:16.120+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.107 seconds
[2024-03-14T11:33:46.178+0000] {processor.py:161} INFO - Started process (PID=5143) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:33:46.180+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:33:46.182+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:33:46.182+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:33:46.211+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:33:46.236+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:33:46.236+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:33:46.262+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:33:46.262+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:33:46.283+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.108 seconds
[2024-03-14T11:34:16.558+0000] {processor.py:161} INFO - Started process (PID=5198) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:34:16.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:34:16.562+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:34:16.561+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:34:16.591+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:34:16.620+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:34:16.620+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:34:16.645+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:34:16.645+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:34:16.678+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.123 seconds
[2024-03-14T11:34:46.869+0000] {processor.py:161} INFO - Started process (PID=5253) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:34:46.870+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:34:46.872+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:34:46.872+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:34:46.903+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:34:46.933+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:34:46.932+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:34:46.957+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:34:46.956+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:34:46.978+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.113 seconds
[2024-03-14T11:35:17.209+0000] {processor.py:161} INFO - Started process (PID=5308) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:35:17.210+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:35:17.212+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:35:17.211+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:35:17.257+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:35:17.282+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:35:17.281+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:35:17.308+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:35:17.307+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:35:17.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.122 seconds
[2024-03-14T11:35:47.375+0000] {processor.py:161} INFO - Started process (PID=5363) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:35:47.376+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:35:47.378+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:35:47.378+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:35:47.415+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:35:47.443+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:35:47.443+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:35:47.471+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:35:47.471+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:35:47.510+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.138 seconds
[2024-03-14T11:36:17.906+0000] {processor.py:161} INFO - Started process (PID=5419) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:36:17.907+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:36:17.908+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:36:17.908+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:36:17.957+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:36:17.989+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:36:17.989+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:36:18.010+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:36:18.010+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:36:18.036+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.132 seconds
[2024-03-14T11:36:48.069+0000] {processor.py:161} INFO - Started process (PID=5475) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:36:48.070+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:36:48.072+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:36:48.072+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:36:48.107+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:36:48.137+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:36:48.137+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:36:48.162+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:36:48.161+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:36:48.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.116 seconds
[2024-03-14T11:37:18.463+0000] {processor.py:161} INFO - Started process (PID=5530) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:37:18.465+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:37:18.467+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:37:18.466+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:37:18.497+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:37:18.524+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:37:18.524+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:37:18.552+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:37:18.551+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:37:18.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.115 seconds
[2024-03-14T11:37:48.651+0000] {processor.py:161} INFO - Started process (PID=5585) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:37:48.652+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:37:48.655+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:37:48.654+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:37:48.698+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:37:48.728+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:37:48.728+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:37:48.751+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:37:48.750+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:37:48.781+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.134 seconds
[2024-03-14T11:38:18.888+0000] {processor.py:161} INFO - Started process (PID=5640) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:38:18.890+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:38:18.892+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:38:18.892+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:38:18.930+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:38:18.959+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:38:18.958+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:38:18.985+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:38:18.985+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:38:19.020+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.135 seconds
[2024-03-14T11:38:49.073+0000] {processor.py:161} INFO - Started process (PID=5695) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:38:49.074+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:38:49.077+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:38:49.076+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:38:49.117+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:38:49.154+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:38:49.154+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:38:49.176+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:38:49.176+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:38:49.200+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.131 seconds
[2024-03-14T11:39:19.605+0000] {processor.py:161} INFO - Started process (PID=5750) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:39:19.606+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:39:19.608+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:39:19.607+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:39:19.660+0000] {processor.py:840} INFO - DAG(s) 'two_separate_groups' retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:39:19.739+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:39:19.738+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-03-14T11:39:19.778+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:39:19.778+0000] {dag.py:3834} INFO - Setting next_dagrun for two_separate_groups to 2024-03-14 00:00:00+00:00, run_after=2024-03-15 00:00:00+00:00
[2024-03-14T11:39:19.815+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.213 seconds
[2024-03-14T11:39:24.315+0000] {processor.py:161} INFO - Started process (PID=5762) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:39:24.316+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:39:24.318+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:39:24.318+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:39:24.372+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:39:24.367+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 109, in <module>
    source_objects=[f"gs://{BUCKET}/raw/{parquet_file}"]
NameError: name 'parquet_file' is not defined
[2024-03-14T11:39:24.373+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:39:24.404+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.093 seconds
[2024-03-14T11:39:54.578+0000] {processor.py:161} INFO - Started process (PID=5816) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:39:54.579+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:39:54.586+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:39:54.586+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:39:54.613+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:39:54.611+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 109, in <module>
    source_objects=[f"gs://{BUCKET}/raw/{parquet_file}"]
NameError: name 'parquet_file' is not defined
[2024-03-14T11:39:54.615+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:39:54.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.057 seconds
[2024-03-14T11:39:59.828+0000] {processor.py:161} INFO - Started process (PID=5838) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:39:59.829+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:39:59.831+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:39:59.831+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:39:59.841+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:39:59.840+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<fstring>", line 1
    (chicago_crime_data_{dataset_number}.parquet)
                        ^
SyntaxError: invalid syntax
[2024-03-14T11:39:59.841+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:39:59.858+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.032 seconds
[2024-03-14T11:40:29.938+0000] {processor.py:161} INFO - Started process (PID=5889) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:40:29.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:40:29.945+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:40:29.944+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:40:29.964+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:40:29.963+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<fstring>", line 1
    (chicago_crime_data_{dataset_number}.parquet)
                        ^
SyntaxError: invalid syntax
[2024-03-14T11:40:29.964+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:40:29.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.055 seconds
[2024-03-14T11:40:32.270+0000] {processor.py:161} INFO - Started process (PID=5895) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:40:32.271+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:40:32.274+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:40:32.273+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:40:32.320+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:40:32.307+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:40:32.321+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:40:32.338+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.070 seconds
[2024-03-14T11:40:40.625+0000] {processor.py:161} INFO - Started process (PID=5906) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:40:40.626+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:40:40.628+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:40:40.628+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:40:40.671+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:40:40.667+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:40:40.672+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:40:40.698+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.077 seconds
[2024-03-14T11:41:10.997+0000] {processor.py:161} INFO - Started process (PID=5961) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:41:10.998+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:41:11.000+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:41:10.999+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:41:11.039+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:41:11.031+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:41:11.040+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:41:11.065+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.071 seconds
[2024-03-14T11:41:41.236+0000] {processor.py:161} INFO - Started process (PID=6016) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:41:41.237+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:41:41.238+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:41:41.237+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:41:41.268+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:41:41.264+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:41:41.270+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:41:41.290+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.058 seconds
[2024-03-14T11:42:11.437+0000] {processor.py:161} INFO - Started process (PID=6071) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:42:11.438+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:42:11.439+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:42:11.438+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:42:11.473+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:42:11.466+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:42:11.474+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:42:11.499+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.065 seconds
[2024-03-14T11:42:41.596+0000] {processor.py:161} INFO - Started process (PID=6126) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:42:41.597+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:42:41.598+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:42:41.598+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:42:41.629+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:42:41.625+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:42:41.630+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:42:41.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.053 seconds
[2024-03-14T11:43:11.721+0000] {processor.py:161} INFO - Started process (PID=6182) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:43:11.722+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:43:11.723+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:43:11.723+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:43:11.767+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:43:11.763+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:43:11.768+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:43:11.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.072 seconds
[2024-03-14T11:43:42.294+0000] {processor.py:161} INFO - Started process (PID=6234) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:43:42.296+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:43:42.297+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:43:42.296+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:43:42.331+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:43:42.325+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:43:42.332+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:43:42.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.058 seconds
[2024-03-14T11:44:13.100+0000] {processor.py:161} INFO - Started process (PID=6289) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:44:13.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:44:13.102+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:44:13.101+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:44:13.133+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:44:13.129+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:44:13.136+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:44:13.153+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.057 seconds
[2024-03-14T11:44:43.925+0000] {processor.py:161} INFO - Started process (PID=6344) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:44:43.926+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:44:43.927+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:44:43.927+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:44:43.957+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:44:43.953+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:44:43.958+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:44:43.976+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.055 seconds
[2024-03-14T11:45:14.084+0000] {processor.py:161} INFO - Started process (PID=6399) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:45:14.085+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:45:14.086+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:45:14.086+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:45:14.123+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:45:14.119+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:45:14.123+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:45:14.312+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.231 seconds
[2024-03-14T11:45:44.822+0000] {processor.py:161} INFO - Started process (PID=6454) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:45:44.823+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:45:44.824+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:45:44.824+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:45:44.855+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:45:44.850+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:45:44.856+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:45:44.873+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.054 seconds
[2024-03-14T11:46:15.047+0000] {processor.py:161} INFO - Started process (PID=6508) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:46:15.048+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:46:15.049+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:46:15.049+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:46:15.089+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:46:15.076+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:46:15.089+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:46:15.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.076 seconds
[2024-03-14T11:46:45.735+0000] {processor.py:161} INFO - Started process (PID=6563) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:46:45.737+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:46:45.740+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:46:45.739+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:46:45.780+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:46:45.776+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:46:45.781+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:46:45.819+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.091 seconds
[2024-03-14T11:47:16.283+0000] {processor.py:161} INFO - Started process (PID=6618) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:47:16.284+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:47:16.286+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:47:16.285+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:47:16.329+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:47:16.325+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:47:16.330+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:47:16.356+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.076 seconds
[2024-03-14T11:47:46.546+0000] {processor.py:161} INFO - Started process (PID=6673) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:47:46.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:47:46.549+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:47:46.548+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:47:46.586+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:47:46.582+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:47:46.586+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:47:46.611+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.069 seconds
[2024-03-14T11:48:16.714+0000] {processor.py:161} INFO - Started process (PID=6728) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:48:16.715+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:48:16.716+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:48:16.716+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:48:16.758+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:48:16.753+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:48:16.759+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:48:16.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.066 seconds
[2024-03-14T11:48:47.133+0000] {processor.py:161} INFO - Started process (PID=6783) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:48:47.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:48:47.136+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:48:47.135+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:48:47.180+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:48:47.176+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:48:47.180+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:48:47.205+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.077 seconds
[2024-03-14T11:49:17.492+0000] {processor.py:161} INFO - Started process (PID=6839) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:49:17.493+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:49:17.494+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:49:17.494+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:49:17.534+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:49:17.527+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:49:17.535+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:49:17.566+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.078 seconds
[2024-03-14T11:49:48.495+0000] {processor.py:161} INFO - Started process (PID=6894) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:49:48.496+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:49:48.497+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:49:48.497+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:49:48.534+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:49:48.527+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:49:48.535+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:49:48.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.060 seconds
[2024-03-14T11:50:19.071+0000] {processor.py:161} INFO - Started process (PID=6950) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:50:19.072+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:50:19.074+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:50:19.073+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:50:19.129+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:50:19.125+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:50:19.130+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:50:19.149+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.082 seconds
[2024-03-14T11:50:49.211+0000] {processor.py:161} INFO - Started process (PID=7005) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:50:49.213+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:50:49.214+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:50:49.214+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:50:49.264+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:50:49.258+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:50:49.265+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:50:49.301+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.095 seconds
[2024-03-14T11:51:19.393+0000] {processor.py:161} INFO - Started process (PID=7060) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:51:19.394+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:51:19.394+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:51:19.394+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:51:19.429+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:51:19.425+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:51:19.429+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:51:19.464+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.074 seconds
[2024-03-14T11:51:49.746+0000] {processor.py:161} INFO - Started process (PID=7116) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:51:49.747+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:51:49.748+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:51:49.748+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:51:49.788+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:51:49.782+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:51:49.789+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:51:49.824+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.081 seconds
[2024-03-14T11:52:20.442+0000] {processor.py:161} INFO - Started process (PID=7171) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:52:20.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:52:20.444+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:52:20.444+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:52:20.483+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:52:20.478+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:52:20.484+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:52:20.510+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.070 seconds
[2024-03-14T11:52:50.770+0000] {processor.py:161} INFO - Started process (PID=7226) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:52:50.771+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:52:50.772+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:52:50.772+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:52:50.814+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:52:50.810+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:52:50.814+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:52:50.842+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.075 seconds
[2024-03-14T11:53:21.412+0000] {processor.py:161} INFO - Started process (PID=7281) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:53:21.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:53:21.414+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:53:21.414+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:53:21.460+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:53:21.450+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:53:21.460+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:53:21.489+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.081 seconds
[2024-03-14T11:53:51.862+0000] {processor.py:161} INFO - Started process (PID=7336) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:53:51.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:53:51.864+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:53:51.864+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:53:51.909+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:53:51.905+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:53:51.910+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:53:51.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.102 seconds
[2024-03-14T11:54:22.006+0000] {processor.py:161} INFO - Started process (PID=7391) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:54:22.007+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:54:22.008+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:54:22.008+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:54:22.086+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:54:22.080+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:54:22.087+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:54:22.108+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.105 seconds
[2024-03-14T11:54:52.226+0000] {processor.py:161} INFO - Started process (PID=7446) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:54:52.227+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:54:52.228+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:54:52.228+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:54:52.275+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:54:52.269+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:54:52.276+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:54:52.302+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.079 seconds
[2024-03-14T11:55:22.945+0000] {processor.py:161} INFO - Started process (PID=7501) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:55:22.946+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:55:22.948+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:55:22.947+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:55:22.989+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:55:22.981+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:55:22.990+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:55:23.010+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.067 seconds
[2024-03-14T11:55:53.286+0000] {processor.py:161} INFO - Started process (PID=7556) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:55:53.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:55:53.289+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:55:53.288+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:55:53.326+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:55:53.321+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:55:53.326+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:55:53.347+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.064 seconds
[2024-03-14T11:56:23.936+0000] {processor.py:161} INFO - Started process (PID=7611) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:56:23.937+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:56:23.938+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:56:23.938+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:56:23.974+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:56:23.971+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:56:23.975+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:56:23.999+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.065 seconds
[2024-03-14T11:56:54.467+0000] {processor.py:161} INFO - Started process (PID=7667) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:56:54.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:56:54.469+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:56:54.469+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:56:54.504+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:56:54.499+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:56:54.505+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:56:54.527+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.063 seconds
[2024-03-14T11:57:25.267+0000] {processor.py:161} INFO - Started process (PID=7722) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:57:25.268+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:57:25.269+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:57:25.269+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:57:25.307+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:57:25.303+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:57:25.307+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:57:25.322+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.058 seconds
[2024-03-14T11:57:55.854+0000] {processor.py:161} INFO - Started process (PID=7778) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:57:55.855+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:57:55.856+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:57:55.856+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:57:55.897+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:57:55.891+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:57:55.898+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:57:55.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.072 seconds
[2024-03-14T11:58:26.561+0000] {processor.py:161} INFO - Started process (PID=7834) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:58:26.562+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:58:26.563+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:58:26.562+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:58:26.638+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:58:26.629+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:58:26.638+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:58:26.669+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.112 seconds
[2024-03-14T11:58:57.606+0000] {processor.py:161} INFO - Started process (PID=7889) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:58:57.610+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:58:57.613+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:58:57.612+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:58:57.649+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:58:57.644+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:58:57.649+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:58:57.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.069 seconds
[2024-03-14T11:59:27.920+0000] {processor.py:161} INFO - Started process (PID=7944) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:59:27.921+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:59:27.922+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:59:27.921+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:59:27.987+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:59:27.982+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:59:27.988+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:59:28.012+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.095 seconds
[2024-03-14T11:59:58.083+0000] {processor.py:161} INFO - Started process (PID=7999) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T11:59:58.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T11:59:58.085+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:59:58.085+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T11:59:58.119+0000] {logging_mixin.py:188} INFO - [2024-03-14T11:59:58.114+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T11:59:58.120+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T11:59:58.143+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.063 seconds
[2024-03-14T12:00:28.285+0000] {processor.py:161} INFO - Started process (PID=8054) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:00:28.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:00:28.288+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:00:28.288+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:00:28.342+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:00:28.336+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:00:28.343+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:00:28.361+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.079 seconds
[2024-03-14T12:00:58.624+0000] {processor.py:161} INFO - Started process (PID=8109) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:00:58.626+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:00:58.630+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:00:58.628+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:00:58.682+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:00:58.678+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:00:58.683+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:00:58.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.092 seconds
[2024-03-14T12:01:28.814+0000] {processor.py:161} INFO - Started process (PID=8164) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:01:28.815+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:01:28.816+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:01:28.815+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:01:28.852+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:01:28.847+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:01:28.852+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:01:28.880+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.071 seconds
[2024-03-14T12:01:59.006+0000] {processor.py:161} INFO - Started process (PID=8219) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:01:59.007+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:01:59.009+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:01:59.008+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:01:59.041+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:01:59.036+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:01:59.042+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:01:59.057+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.054 seconds
[2024-03-14T12:02:29.199+0000] {processor.py:161} INFO - Started process (PID=8274) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:02:29.200+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:02:29.201+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:02:29.201+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:02:29.240+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:02:29.236+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:02:29.241+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:02:29.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.059 seconds
[2024-03-14T12:02:59.747+0000] {processor.py:161} INFO - Started process (PID=8329) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:02:59.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:02:59.749+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:02:59.748+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:02:59.784+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:02:59.780+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:02:59.784+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:02:59.802+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.058 seconds
[2024-03-14T12:03:30.508+0000] {processor.py:161} INFO - Started process (PID=8385) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:03:30.509+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:03:30.510+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:03:30.510+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:03:30.548+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:03:30.544+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:03:30.548+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:03:30.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.070 seconds
[2024-03-14T12:04:01.319+0000] {processor.py:161} INFO - Started process (PID=8440) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:04:01.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:04:01.329+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:04:01.328+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:04:01.380+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:04:01.375+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:04:01.380+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:04:01.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.095 seconds
[2024-03-14T12:04:31.643+0000] {processor.py:161} INFO - Started process (PID=8496) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:04:31.644+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:04:31.646+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:04:31.645+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:04:31.686+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:04:31.681+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:04:31.687+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:04:31.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.061 seconds
[2024-03-14T12:05:02.178+0000] {processor.py:161} INFO - Started process (PID=8551) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:05:02.179+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:05:02.180+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:05:02.180+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:05:02.214+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:05:02.210+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:05:02.215+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:05:02.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.055 seconds
[2024-03-14T12:05:32.377+0000] {processor.py:161} INFO - Started process (PID=8607) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:05:32.379+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:05:32.380+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:05:32.380+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:05:32.421+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:05:32.416+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:05:32.421+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:05:32.443+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.070 seconds
[2024-03-14T12:06:02.574+0000] {processor.py:161} INFO - Started process (PID=8662) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:06:02.575+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:06:02.576+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:06:02.576+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:06:02.609+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:06:02.604+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:06:02.609+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:06:02.625+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.056 seconds
[2024-03-14T12:06:32.684+0000] {processor.py:161} INFO - Started process (PID=8717) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:06:32.686+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:06:32.687+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:06:32.687+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:06:32.730+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:06:32.725+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:06:32.731+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:06:32.747+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.065 seconds
[2024-03-14T12:07:02.818+0000] {processor.py:161} INFO - Started process (PID=8772) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:07:02.819+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:07:02.820+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:07:02.820+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:07:02.868+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:07:02.863+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:07:02.869+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:07:02.899+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.084 seconds
[2024-03-14T12:07:33.369+0000] {processor.py:161} INFO - Started process (PID=8826) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:07:33.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:07:33.371+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:07:33.370+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:07:33.402+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:07:33.398+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:07:33.402+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:07:33.421+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.055 seconds
[2024-03-14T12:08:04.003+0000] {processor.py:161} INFO - Started process (PID=8881) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:08:04.004+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:08:04.005+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:08:04.004+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:08:04.039+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:08:04.035+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:08:04.040+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:08:04.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.060 seconds
[2024-03-14T12:08:34.137+0000] {processor.py:161} INFO - Started process (PID=8936) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:08:34.138+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:08:34.139+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:08:34.139+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:08:34.168+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:08:34.164+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:08:34.169+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:08:34.184+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.049 seconds
[2024-03-14T12:09:04.533+0000] {processor.py:161} INFO - Started process (PID=8992) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:09:04.534+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:09:04.536+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:09:04.535+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:09:04.572+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:09:04.569+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:09:04.573+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:09:04.590+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.061 seconds
[2024-03-14T12:09:35.312+0000] {processor.py:161} INFO - Started process (PID=9048) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:09:35.313+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:09:35.314+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:09:35.314+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:09:35.345+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:09:35.341+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:09:35.345+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:09:35.361+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.051 seconds
[2024-03-14T12:10:05.413+0000] {processor.py:161} INFO - Started process (PID=9103) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:10:05.414+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:10:05.415+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:10:05.415+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:10:05.446+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:10:05.442+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:10:05.447+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:10:05.463+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.052 seconds
[2024-03-14T12:10:35.538+0000] {processor.py:161} INFO - Started process (PID=9158) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:10:35.539+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:10:35.540+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:10:35.539+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:10:35.566+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:10:35.562+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:10:35.566+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:10:35.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.055 seconds
[2024-03-14T12:11:05.849+0000] {processor.py:161} INFO - Started process (PID=9214) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:11:05.850+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:11:05.850+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:11:05.850+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:11:05.885+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:11:05.880+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:11:05.886+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:11:05.905+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.059 seconds
[2024-03-14T12:11:36.165+0000] {processor.py:161} INFO - Started process (PID=9269) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:11:36.166+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:11:36.167+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:11:36.167+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:11:36.198+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:11:36.194+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:11:36.199+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:11:36.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.054 seconds
[2024-03-14T12:12:06.263+0000] {processor.py:161} INFO - Started process (PID=9325) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:12:06.264+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:12:06.265+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:12:06.264+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:12:06.297+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:12:06.292+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:12:06.298+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:12:06.320+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.060 seconds
[2024-03-14T12:12:36.415+0000] {processor.py:161} INFO - Started process (PID=9381) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:12:36.416+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:12:36.417+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:12:36.416+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:12:36.450+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:12:36.445+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:12:36.451+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:12:36.472+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.060 seconds
[2024-03-14T12:13:06.569+0000] {processor.py:161} INFO - Started process (PID=9436) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:13:06.570+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:13:06.570+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:13:06.570+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:13:06.601+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:13:06.597+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:13:06.602+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:13:06.620+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.054 seconds
[2024-03-14T12:13:36.732+0000] {processor.py:161} INFO - Started process (PID=9491) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:13:36.733+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:13:36.735+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:13:36.735+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:13:36.781+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:13:36.776+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:13:36.782+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:13:36.810+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.081 seconds
[2024-03-14T12:14:06.875+0000] {processor.py:161} INFO - Started process (PID=9546) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:14:06.876+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:14:06.877+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:14:06.876+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:14:06.906+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:14:06.902+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:14:06.906+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:14:06.921+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.049 seconds
[2024-03-14T12:14:37.130+0000] {processor.py:161} INFO - Started process (PID=9601) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:14:37.131+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:14:37.132+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:14:37.132+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:14:37.170+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:14:37.165+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:14:37.171+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:14:37.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.061 seconds
[2024-03-14T12:15:07.474+0000] {processor.py:161} INFO - Started process (PID=9656) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:15:07.475+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:15:07.475+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:15:07.475+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:15:07.505+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:15:07.501+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:15:07.506+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:15:07.522+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.051 seconds
[2024-03-14T12:15:37.671+0000] {processor.py:161} INFO - Started process (PID=9711) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:15:37.672+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:15:37.673+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:15:37.673+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:15:37.701+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:15:37.698+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:15:37.702+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:15:37.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.050 seconds
[2024-03-14T12:16:08.384+0000] {processor.py:161} INFO - Started process (PID=9766) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:16:08.385+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:16:08.386+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:16:08.386+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:16:08.418+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:16:08.413+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:16:08.418+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:16:08.435+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.054 seconds
[2024-03-14T12:16:39.399+0000] {processor.py:161} INFO - Started process (PID=9827) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:16:39.400+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:16:39.401+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:16:39.400+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:16:39.432+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:16:39.427+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:16:39.433+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:16:39.454+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.058 seconds
[2024-03-14T12:17:09.505+0000] {processor.py:161} INFO - Started process (PID=9883) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:17:09.506+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:17:09.508+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:17:09.507+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:17:09.537+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:17:09.533+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:17:09.538+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:17:09.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.067 seconds
[2024-03-14T12:17:39.703+0000] {processor.py:161} INFO - Started process (PID=9938) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:17:39.704+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:17:39.705+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:17:39.704+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:17:39.733+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:17:39.729+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:17:39.734+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:17:39.752+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.052 seconds
[2024-03-14T12:18:10.054+0000] {processor.py:161} INFO - Started process (PID=9993) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:18:10.055+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:18:10.056+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:18:10.056+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:18:10.085+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:18:10.081+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:18:10.085+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:18:10.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.057 seconds
[2024-03-14T12:18:40.182+0000] {processor.py:161} INFO - Started process (PID=10048) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:18:40.184+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:18:40.185+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:18:40.184+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:18:40.217+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:18:40.213+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:18:40.218+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:18:40.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.061 seconds
[2024-03-14T12:19:10.509+0000] {processor.py:161} INFO - Started process (PID=10103) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:19:10.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:19:10.512+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:19:10.511+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:19:10.555+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:19:10.550+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:19:10.556+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:19:10.578+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.072 seconds
[2024-03-14T12:19:41.267+0000] {processor.py:161} INFO - Started process (PID=10158) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:19:41.269+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:19:41.270+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:19:41.269+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:19:41.303+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:19:41.298+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:19:41.304+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:19:41.327+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.063 seconds
[2024-03-14T12:20:12.179+0000] {processor.py:161} INFO - Started process (PID=10213) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:20:12.181+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:20:12.182+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:20:12.182+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:20:12.213+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:20:12.210+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:20:12.214+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:20:12.230+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.054 seconds
[2024-03-14T12:20:43.115+0000] {processor.py:161} INFO - Started process (PID=10269) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:20:43.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:20:43.117+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:20:43.117+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:20:43.144+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:20:43.140+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:20:43.145+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:20:43.161+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.048 seconds
[2024-03-14T12:21:14.026+0000] {processor.py:161} INFO - Started process (PID=10324) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:21:14.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:21:14.028+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:21:14.027+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:21:14.064+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:21:14.056+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:21:14.066+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:21:14.085+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.062 seconds
[2024-03-14T12:21:44.879+0000] {processor.py:161} INFO - Started process (PID=10379) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:21:44.881+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:21:44.882+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:21:44.882+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:21:44.914+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:21:44.910+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:21:44.915+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:21:44.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.067 seconds
[2024-03-14T12:22:15.224+0000] {processor.py:161} INFO - Started process (PID=10434) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:22:15.225+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:22:15.226+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:22:15.225+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:22:15.256+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:22:15.252+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:22:15.257+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:22:15.281+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.060 seconds
[2024-03-14T12:22:45.645+0000] {processor.py:161} INFO - Started process (PID=10489) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:22:45.646+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:22:45.647+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:22:45.647+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:22:45.675+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:22:45.671+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:22:45.675+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:22:45.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.050 seconds
[2024-03-14T12:23:15.886+0000] {processor.py:161} INFO - Started process (PID=10544) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:23:15.887+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:23:15.887+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:23:15.887+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:23:15.915+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:23:15.912+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:23:15.916+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:23:15.934+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.051 seconds
[2024-03-14T12:23:46.108+0000] {processor.py:161} INFO - Started process (PID=10599) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:23:46.109+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:23:46.110+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:23:46.109+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:23:46.142+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:23:46.138+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:23:46.143+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:23:46.163+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.058 seconds
[2024-03-14T12:24:16.248+0000] {processor.py:161} INFO - Started process (PID=10654) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:24:16.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:24:16.250+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:24:16.250+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:24:16.274+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:24:16.271+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:24:16.275+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:24:16.290+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.044 seconds
[2024-03-14T12:24:46.426+0000] {processor.py:161} INFO - Started process (PID=10709) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:24:46.427+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:24:46.429+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:24:46.428+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:24:46.461+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:24:46.456+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:24:46.462+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:24:46.480+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.056 seconds
[2024-03-14T12:25:16.557+0000] {processor.py:161} INFO - Started process (PID=10764) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:25:16.558+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:25:16.559+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:25:16.558+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:25:16.591+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:25:16.587+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:25:16.591+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:25:16.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.053 seconds
[2024-03-14T12:25:46.726+0000] {processor.py:161} INFO - Started process (PID=10819) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:25:46.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:25:46.728+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:25:46.727+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:25:46.757+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:25:46.753+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:25:46.757+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:25:46.775+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.052 seconds
[2024-03-14T12:26:17.172+0000] {processor.py:161} INFO - Started process (PID=10875) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:26:17.173+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:26:17.174+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:26:17.174+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:26:17.207+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:26:17.202+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:26:17.209+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:26:17.236+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.066 seconds
[2024-03-14T12:26:47.900+0000] {processor.py:161} INFO - Started process (PID=10930) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:26:47.900+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:26:47.901+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:26:47.901+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:26:47.931+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:26:47.927+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:26:47.931+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:26:47.947+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.050 seconds
[2024-03-14T12:27:17.996+0000] {processor.py:161} INFO - Started process (PID=10985) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:27:17.997+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:27:17.998+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:27:17.998+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:27:18.026+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:27:18.022+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:27:18.027+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:27:18.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.050 seconds
[2024-03-14T12:27:48.765+0000] {processor.py:161} INFO - Started process (PID=11039) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:27:48.766+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:27:48.767+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:27:48.767+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:27:48.828+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:27:48.819+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:27:48.831+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:27:48.865+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.103 seconds
[2024-03-14T12:28:19.328+0000] {processor.py:161} INFO - Started process (PID=11094) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:28:19.328+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:28:19.329+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:28:19.329+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:28:19.362+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:28:19.359+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:28:19.363+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:28:19.380+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.055 seconds
[2024-03-14T12:28:49.896+0000] {processor.py:161} INFO - Started process (PID=11149) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:28:49.897+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:28:49.898+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:28:49.897+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:28:49.929+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:28:49.925+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:28:49.929+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:28:49.946+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.053 seconds
[2024-03-14T12:29:20.632+0000] {processor.py:161} INFO - Started process (PID=11204) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:29:20.633+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:29:20.634+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:29:20.634+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:29:20.695+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:29:20.671+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:29:20.702+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:29:20.718+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.089 seconds
[2024-03-14T12:29:51.372+0000] {processor.py:161} INFO - Started process (PID=11259) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:29:51.374+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:29:51.376+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:29:51.375+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:29:51.409+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:29:51.405+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:29:51.410+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:29:51.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.059 seconds
[2024-03-14T12:30:21.968+0000] {processor.py:161} INFO - Started process (PID=11315) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:30:21.969+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:30:21.972+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:30:21.971+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:30:22.017+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:30:22.002+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:30:22.018+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:30:22.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.074 seconds
[2024-03-14T12:30:52.428+0000] {processor.py:161} INFO - Started process (PID=11370) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:30:52.430+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:30:52.431+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:30:52.431+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:30:52.477+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:30:52.472+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:30:52.478+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:30:52.496+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.070 seconds
[2024-03-14T12:31:22.649+0000] {processor.py:161} INFO - Started process (PID=11425) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:31:22.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:31:22.652+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:31:22.651+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:31:22.683+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:31:22.680+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:31:22.684+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:31:22.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.055 seconds
[2024-03-14T12:31:52.999+0000] {processor.py:161} INFO - Started process (PID=11481) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:31:53.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:31:53.001+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:31:53.001+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:31:53.035+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:31:53.029+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:31:53.036+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:31:53.053+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.057 seconds
[2024-03-14T12:32:23.108+0000] {processor.py:161} INFO - Started process (PID=11537) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:32:23.109+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:32:23.110+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:32:23.109+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:32:23.147+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:32:23.141+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:32:23.148+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:32:23.172+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.067 seconds
[2024-03-14T12:32:54.129+0000] {processor.py:161} INFO - Started process (PID=11592) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:32:54.130+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:32:54.130+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:32:54.130+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:32:54.158+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:32:54.153+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:32:54.158+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:32:54.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.047 seconds
[2024-03-14T12:33:25.023+0000] {processor.py:161} INFO - Started process (PID=11648) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:33:25.024+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:33:25.025+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:33:25.025+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:33:25.057+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:33:25.053+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:33:25.058+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:33:25.083+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.063 seconds
[2024-03-14T12:33:55.645+0000] {processor.py:161} INFO - Started process (PID=11703) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:33:55.646+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:33:55.647+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:33:55.646+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:33:55.677+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:33:55.672+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:33:55.678+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:33:55.707+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.065 seconds
[2024-03-14T12:34:25.888+0000] {processor.py:161} INFO - Started process (PID=11758) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:34:25.889+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:34:25.890+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:34:25.890+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:34:25.922+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:34:25.918+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:34:25.923+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:34:25.976+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.091 seconds
[2024-03-14T12:34:56.036+0000] {processor.py:161} INFO - Started process (PID=11813) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:34:56.037+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:34:56.038+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:34:56.038+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:34:56.070+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:34:56.066+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:34:56.071+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:34:56.089+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.055 seconds
[2024-03-14T12:35:26.207+0000] {processor.py:161} INFO - Started process (PID=11868) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:35:26.207+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:35:26.208+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:35:26.208+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:35:26.242+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:35:26.237+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:35:26.242+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:35:26.260+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.056 seconds
[2024-03-14T12:35:56.442+0000] {processor.py:161} INFO - Started process (PID=11923) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:35:56.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:35:56.444+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:35:56.443+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:35:56.472+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:35:56.468+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:35:56.473+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:35:56.488+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.048 seconds
[2024-03-14T12:36:26.802+0000] {processor.py:161} INFO - Started process (PID=11978) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:36:26.802+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:36:26.803+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:36:26.803+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:36:26.835+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:36:26.831+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:36:26.836+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:36:26.872+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.074 seconds
[2024-03-14T12:36:56.939+0000] {processor.py:161} INFO - Started process (PID=12033) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:36:56.940+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:36:56.941+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:36:56.941+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:36:56.973+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:36:56.969+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:36:56.974+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:36:56.992+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.055 seconds
[2024-03-14T12:37:27.112+0000] {processor.py:161} INFO - Started process (PID=12087) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:37:27.113+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:37:27.114+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:37:27.113+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:37:27.146+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:37:27.141+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:37:27.147+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:37:27.165+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.055 seconds
[2024-03-14T12:37:57.345+0000] {processor.py:161} INFO - Started process (PID=12142) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:37:57.346+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:37:57.347+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:37:57.347+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:37:57.380+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:37:57.376+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:37:57.381+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:37:57.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.058 seconds
[2024-03-14T12:38:27.742+0000] {processor.py:161} INFO - Started process (PID=12198) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:38:27.743+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:38:27.745+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:38:27.744+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:38:27.780+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:38:27.776+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:38:27.781+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:38:27.798+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.058 seconds
[2024-03-14T12:38:58.037+0000] {processor.py:161} INFO - Started process (PID=12253) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:38:58.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:38:58.039+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:38:58.039+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:38:58.070+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:38:58.066+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:38:58.071+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:38:58.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.057 seconds
[2024-03-14T12:39:28.231+0000] {processor.py:161} INFO - Started process (PID=12309) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:39:28.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:39:28.233+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:39:28.232+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:39:28.265+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:39:28.260+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:39:28.265+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:39:28.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.108 seconds
[2024-03-14T12:39:59.336+0000] {processor.py:161} INFO - Started process (PID=12364) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:39:59.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:39:59.338+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:39:59.338+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:39:59.375+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:39:59.371+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:39:59.376+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:39:59.396+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.063 seconds
[2024-03-14T12:40:29.572+0000] {processor.py:161} INFO - Started process (PID=12420) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:40:29.575+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:40:29.577+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:40:29.576+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:40:29.617+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:40:29.612+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:40:29.617+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:40:29.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.067 seconds
[2024-03-14T12:41:00.594+0000] {processor.py:161} INFO - Started process (PID=12476) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:41:00.595+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:41:00.596+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:41:00.596+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:41:00.635+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:41:00.630+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:41:00.636+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:41:00.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.067 seconds
[2024-03-14T12:41:31.353+0000] {processor.py:161} INFO - Started process (PID=12531) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:41:31.355+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:41:31.356+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:41:31.356+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:41:31.400+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:41:31.393+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:41:31.401+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:41:31.432+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.082 seconds
[2024-03-14T12:42:01.873+0000] {processor.py:161} INFO - Started process (PID=12586) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:42:01.874+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:42:01.876+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:42:01.876+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:42:01.914+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:42:01.907+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:42:01.915+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:42:01.933+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.064 seconds
[2024-03-14T12:42:32.374+0000] {processor.py:161} INFO - Started process (PID=12641) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:42:32.375+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:42:32.376+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:42:32.376+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:42:32.405+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:42:32.402+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:42:32.406+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:42:32.421+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.049 seconds
[2024-03-14T12:43:02.745+0000] {processor.py:161} INFO - Started process (PID=12696) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:43:02.746+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:43:02.747+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:43:02.747+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:43:02.775+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:43:02.772+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:43:02.775+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:43:02.793+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.053 seconds
[2024-03-14T12:43:33.083+0000] {processor.py:161} INFO - Started process (PID=12752) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:43:33.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:43:33.085+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:43:33.085+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:43:33.117+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:43:33.112+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:43:33.117+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:43:33.137+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.056 seconds
[2024-03-14T12:44:03.553+0000] {processor.py:161} INFO - Started process (PID=12807) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:44:03.554+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:44:03.556+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:44:03.555+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:44:03.588+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:44:03.584+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:44:03.589+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:44:03.606+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.055 seconds
[2024-03-14T12:44:34.124+0000] {processor.py:161} INFO - Started process (PID=12862) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:44:34.125+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:44:34.126+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:44:34.126+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:44:34.162+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:44:34.156+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:44:34.163+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:44:34.182+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.061 seconds
[2024-03-14T12:45:04.953+0000] {processor.py:161} INFO - Started process (PID=12917) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:45:04.954+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:45:04.956+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:45:04.956+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:45:05.061+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:45:05.040+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:45:05.063+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:45:05.103+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.154 seconds
[2024-03-14T12:45:35.273+0000] {processor.py:161} INFO - Started process (PID=12972) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:45:35.275+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:45:35.277+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:45:35.277+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:45:35.369+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:45:35.363+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:45:35.370+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:45:35.418+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.149 seconds
[2024-03-14T12:46:05.600+0000] {processor.py:161} INFO - Started process (PID=13027) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:46:05.601+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:46:05.601+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:46:05.601+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:46:05.640+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:46:05.635+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:46:05.641+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:46:05.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.073 seconds
[2024-03-14T12:46:36.078+0000] {processor.py:161} INFO - Started process (PID=13082) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:46:36.080+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:46:36.081+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:46:36.081+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:46:36.128+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:46:36.122+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:46:36.129+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:46:36.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.089 seconds
[2024-03-14T12:47:06.555+0000] {processor.py:161} INFO - Started process (PID=13137) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:47:06.561+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:47:06.563+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:47:06.562+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:47:06.605+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:47:06.600+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:47:06.606+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:47:06.626+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.075 seconds
[2024-03-14T12:47:36.929+0000] {processor.py:161} INFO - Started process (PID=13192) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:47:36.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:47:36.931+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:47:36.931+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:47:36.978+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:47:36.971+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:47:36.979+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:47:37.002+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.077 seconds
[2024-03-14T12:48:07.204+0000] {processor.py:161} INFO - Started process (PID=13247) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:48:07.205+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:48:07.207+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:48:07.206+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:48:07.251+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:48:07.246+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:48:07.252+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:48:07.271+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.073 seconds
[2024-03-14T12:48:38.234+0000] {processor.py:161} INFO - Started process (PID=13302) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:48:38.236+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:48:38.237+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:48:38.236+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:48:38.296+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:48:38.287+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:48:38.297+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:48:38.337+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.106 seconds
[2024-03-14T12:49:08.862+0000] {processor.py:161} INFO - Started process (PID=13357) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:49:08.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:49:08.864+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:49:08.864+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:49:08.911+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:49:08.903+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:49:08.912+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:49:08.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.085 seconds
[2024-03-14T12:49:39.241+0000] {processor.py:161} INFO - Started process (PID=13412) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:49:39.242+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:49:39.243+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:49:39.243+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:49:39.298+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:49:39.292+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:49:39.299+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:49:39.324+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.087 seconds
[2024-03-14T12:50:09.744+0000] {processor.py:161} INFO - Started process (PID=13467) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:50:09.745+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:50:09.746+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:50:09.746+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:50:09.790+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:50:09.783+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:50:09.791+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:50:09.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.070 seconds
[2024-03-14T12:50:40.060+0000] {processor.py:161} INFO - Started process (PID=13522) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:50:40.062+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:50:40.063+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:50:40.062+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:50:40.119+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:50:40.112+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:50:40.120+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:50:40.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.093 seconds
[2024-03-14T12:51:10.410+0000] {processor.py:161} INFO - Started process (PID=13577) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:51:10.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:51:10.413+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:51:10.412+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:51:10.469+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:51:10.463+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:51:10.470+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:51:10.500+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.094 seconds
[2024-03-14T12:51:40.686+0000] {processor.py:161} INFO - Started process (PID=13632) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:51:40.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:51:40.688+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:51:40.688+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:51:40.727+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:51:40.723+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:51:40.728+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:51:40.755+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.074 seconds
[2024-03-14T12:52:10.882+0000] {processor.py:161} INFO - Started process (PID=13687) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:52:10.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:52:10.887+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:52:10.886+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:52:10.937+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:52:10.931+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:52:10.938+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:52:10.992+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.114 seconds
[2024-03-14T12:52:41.754+0000] {processor.py:161} INFO - Started process (PID=13743) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:52:41.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:52:41.757+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:52:41.757+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:52:41.816+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:52:41.808+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:52:41.817+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:52:41.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.100 seconds
[2024-03-14T12:53:12.072+0000] {processor.py:161} INFO - Started process (PID=13804) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:53:12.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:53:12.074+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:53:12.074+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:53:12.117+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:53:12.111+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:53:12.118+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:53:12.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.078 seconds
[2024-03-14T12:53:42.585+0000] {processor.py:161} INFO - Started process (PID=13859) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:53:42.587+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:53:42.590+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:53:42.589+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:53:42.644+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:53:42.638+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:53:42.645+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:53:42.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.086 seconds
[2024-03-14T12:54:12.807+0000] {processor.py:161} INFO - Started process (PID=13915) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:54:12.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:54:12.812+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:54:12.811+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:54:12.859+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:54:12.853+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:54:12.860+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:54:12.880+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.092 seconds
[2024-03-14T12:54:43.299+0000] {processor.py:161} INFO - Started process (PID=13970) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:54:43.301+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:54:43.309+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:54:43.308+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:54:43.355+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:54:43.350+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:54:43.355+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:54:43.395+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.098 seconds
[2024-03-14T12:55:13.747+0000] {processor.py:161} INFO - Started process (PID=14025) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:55:13.749+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:55:13.751+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:55:13.750+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:55:13.824+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:55:13.815+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:55:13.826+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:55:13.883+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.140 seconds
[2024-03-14T12:55:44.546+0000] {processor.py:161} INFO - Started process (PID=14081) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:55:44.547+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:55:44.549+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:55:44.548+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:55:44.585+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:55:44.581+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:55:44.586+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:55:44.604+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.062 seconds
[2024-03-14T12:56:15.401+0000] {processor.py:161} INFO - Started process (PID=14136) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:56:15.402+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:56:15.403+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:56:15.403+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:56:15.440+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:56:15.436+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:56:15.441+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:56:15.459+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.060 seconds
[2024-03-14T12:56:45.583+0000] {processor.py:161} INFO - Started process (PID=14191) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:56:45.585+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:56:45.586+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:56:45.586+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:56:45.627+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:56:45.622+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:56:45.628+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:56:45.653+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.072 seconds
[2024-03-14T12:57:15.792+0000] {processor.py:161} INFO - Started process (PID=14247) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:57:15.794+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:57:15.795+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:57:15.795+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:57:15.835+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:57:15.829+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:57:15.836+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:57:15.866+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.077 seconds
[2024-03-14T12:57:45.942+0000] {processor.py:161} INFO - Started process (PID=14302) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:57:45.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:57:45.945+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:57:45.944+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:57:45.995+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:57:45.989+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:57:45.996+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:57:46.023+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.085 seconds
[2024-03-14T12:58:16.411+0000] {processor.py:161} INFO - Started process (PID=14357) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:58:16.412+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:58:16.413+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:58:16.413+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:58:16.451+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:58:16.446+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:58:16.452+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:58:16.474+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.066 seconds
[2024-03-14T12:58:47.179+0000] {processor.py:161} INFO - Started process (PID=14412) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:58:47.180+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:58:47.181+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:58:47.181+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:58:47.216+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:58:47.211+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:58:47.217+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:58:47.235+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.059 seconds
[2024-03-14T12:59:17.967+0000] {processor.py:161} INFO - Started process (PID=14467) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:59:17.968+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:59:17.969+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:59:17.969+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:59:18.006+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:59:18.001+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:59:18.007+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:59:18.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.067 seconds
[2024-03-14T12:59:48.675+0000] {processor.py:161} INFO - Started process (PID=14521) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T12:59:48.676+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T12:59:48.677+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:59:48.677+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T12:59:48.713+0000] {logging_mixin.py:188} INFO - [2024-03-14T12:59:48.708+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T12:59:48.713+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T12:59:48.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.060 seconds
[2024-03-14T13:00:18.991+0000] {processor.py:161} INFO - Started process (PID=14576) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T13:00:18.993+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T13:00:18.995+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:00:18.994+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T13:00:19.069+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:00:19.057+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T13:00:19.070+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T13:00:19.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.125 seconds
[2024-03-14T13:00:49.441+0000] {processor.py:161} INFO - Started process (PID=14631) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T13:00:49.444+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T13:00:49.448+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:00:49.448+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T13:00:49.498+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:00:49.491+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T13:00:49.499+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T13:00:49.529+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.092 seconds
[2024-03-14T13:01:19.775+0000] {processor.py:161} INFO - Started process (PID=14686) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T13:01:19.776+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T13:01:19.777+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:01:19.777+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T13:01:19.810+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:01:19.806+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T13:01:19.813+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T13:01:19.847+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.075 seconds
[2024-03-14T13:01:49.894+0000] {processor.py:161} INFO - Started process (PID=14741) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T13:01:49.895+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T13:01:49.897+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:01:49.896+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T13:01:49.931+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:01:49.926+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T13:01:49.932+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T13:01:49.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.062 seconds
[2024-03-14T13:02:20.601+0000] {processor.py:161} INFO - Started process (PID=14797) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T13:02:20.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T13:02:20.604+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:02:20.603+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T13:02:20.646+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:02:20.641+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T13:02:20.647+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T13:02:20.668+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.071 seconds
[2024-03-14T13:02:51.420+0000] {processor.py:161} INFO - Started process (PID=14852) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T13:02:51.421+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T13:02:51.422+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:02:51.422+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T13:02:51.470+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:02:51.466+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T13:02:51.471+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T13:02:51.515+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.098 seconds
[2024-03-14T13:03:22.405+0000] {processor.py:161} INFO - Started process (PID=14907) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T13:03:22.407+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T13:03:22.408+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:03:22.408+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T13:03:22.452+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:03:22.447+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T13:03:22.453+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T13:03:22.722+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.321 seconds
[2024-03-14T13:03:52.862+0000] {processor.py:161} INFO - Started process (PID=14962) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T13:03:52.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T13:03:52.864+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:03:52.864+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T13:03:52.902+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:03:52.897+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T13:03:52.903+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T13:03:52.922+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.063 seconds
[2024-03-14T13:04:23.196+0000] {processor.py:161} INFO - Started process (PID=15017) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T13:04:23.197+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T13:04:23.198+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:04:23.198+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T13:04:23.241+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:04:23.236+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T13:04:23.242+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T13:04:23.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.073 seconds
[2024-03-14T13:04:53.645+0000] {processor.py:161} INFO - Started process (PID=15071) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T13:04:53.646+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T13:04:53.647+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:04:53.646+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T13:04:53.683+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:04:53.677+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T13:04:53.684+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T13:04:53.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.060 seconds
[2024-03-14T13:05:23.924+0000] {processor.py:161} INFO - Started process (PID=15126) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T13:05:23.925+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T13:05:23.926+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:05:23.926+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T13:05:23.967+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:05:23.962+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T13:05:23.968+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T13:05:23.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.069 seconds
[2024-03-14T13:05:54.159+0000] {processor.py:161} INFO - Started process (PID=15181) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T13:05:54.160+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T13:05:54.161+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:05:54.160+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T13:05:54.199+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:05:54.193+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T13:05:54.200+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T13:05:54.220+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.064 seconds
[2024-03-14T13:06:24.761+0000] {processor.py:161} INFO - Started process (PID=15236) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T13:06:24.763+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T13:06:24.765+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:06:24.764+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T13:06:24.799+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:06:24.794+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T13:06:24.800+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T13:06:24.818+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.060 seconds
[2024-03-14T13:06:55.612+0000] {processor.py:161} INFO - Started process (PID=15292) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T13:06:55.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T13:06:55.615+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:06:55.614+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T13:06:55.655+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:06:55.651+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T13:06:55.656+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T13:06:55.686+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.076 seconds
[2024-03-14T13:07:25.825+0000] {processor.py:161} INFO - Started process (PID=15347) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T13:07:25.826+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T13:07:25.828+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:07:25.828+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T13:07:25.864+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:07:25.859+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T13:07:25.865+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T13:07:25.883+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.062 seconds
[2024-03-14T13:07:56.340+0000] {processor.py:161} INFO - Started process (PID=15402) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T13:07:56.342+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T13:07:56.344+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:07:56.343+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T13:07:56.384+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:07:56.380+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T13:07:56.385+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T13:07:56.406+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.070 seconds
[2024-03-14T13:08:26.728+0000] {processor.py:161} INFO - Started process (PID=15457) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T13:08:26.730+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T13:08:26.731+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:08:26.731+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T13:08:26.770+0000] {logging_mixin.py:188} INFO - [2024-03-14T13:08:26.762+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T13:08:26.771+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T13:08:26.789+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.064 seconds
[2024-03-14T15:24:46.793+0000] {processor.py:161} INFO - Started process (PID=15474) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:24:46.830+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:24:46.908+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:24:46.905+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:24:47.597+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:24:47.531+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:24:47.629+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:24:48.024+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 1.243 seconds
[2024-03-14T15:25:18.997+0000] {processor.py:161} INFO - Started process (PID=16096) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:25:18.998+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:25:19.000+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:25:18.999+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:25:19.066+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:25:19.061+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:25:19.069+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:25:19.093+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.098 seconds
[2024-03-14T15:25:49.176+0000] {processor.py:161} INFO - Started process (PID=16151) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:25:49.177+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:25:49.178+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:25:49.178+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:25:49.225+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:25:49.216+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:25:49.225+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:25:49.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.072 seconds
[2024-03-14T15:26:20.027+0000] {processor.py:161} INFO - Started process (PID=16206) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:26:20.029+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:26:20.030+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:26:20.029+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:26:20.070+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:26:20.062+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:26:20.071+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:26:20.106+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.082 seconds
[2024-03-14T15:26:50.292+0000] {processor.py:161} INFO - Started process (PID=16261) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:26:50.293+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:26:50.295+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:26:50.294+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:26:50.325+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:26:50.321+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:26:50.326+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:26:50.346+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.059 seconds
[2024-03-14T15:27:20.441+0000] {processor.py:161} INFO - Started process (PID=16316) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:27:20.442+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:27:20.443+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:27:20.443+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:27:20.479+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:27:20.475+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:27:20.480+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:27:20.516+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.078 seconds
[2024-03-14T15:27:50.620+0000] {processor.py:161} INFO - Started process (PID=16371) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:27:50.621+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:27:50.622+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:27:50.622+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:27:50.653+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:27:50.649+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:27:50.654+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:27:50.684+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.067 seconds
[2024-03-14T15:28:21.325+0000] {processor.py:161} INFO - Started process (PID=16427) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:28:21.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:28:21.327+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:28:21.326+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:28:21.361+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:28:21.357+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:28:21.362+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:28:21.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.089 seconds
[2024-03-14T15:28:51.507+0000] {processor.py:161} INFO - Started process (PID=16482) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:28:51.508+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:28:51.508+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:28:51.508+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:28:51.541+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:28:51.537+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:28:51.542+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:28:51.576+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.073 seconds
[2024-03-14T15:29:21.885+0000] {processor.py:161} INFO - Started process (PID=16537) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:29:21.886+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:29:21.887+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:29:21.887+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:29:21.917+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:29:21.913+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:29:21.918+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:29:21.981+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.099 seconds
[2024-03-14T15:29:52.242+0000] {processor.py:161} INFO - Started process (PID=16592) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:29:52.244+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:29:52.246+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:29:52.245+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:29:52.296+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:29:52.293+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:29:52.297+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:29:52.312+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.073 seconds
[2024-03-14T15:30:22.372+0000] {processor.py:161} INFO - Started process (PID=16647) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:30:22.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:30:22.375+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:30:22.374+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:30:22.405+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:30:22.401+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:30:22.405+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:30:22.421+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.053 seconds
[2024-03-14T15:30:53.339+0000] {processor.py:161} INFO - Started process (PID=16702) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:30:53.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:30:53.341+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:30:53.340+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:30:53.374+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:30:53.369+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:30:53.374+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:30:53.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.063 seconds
[2024-03-14T15:31:23.677+0000] {processor.py:161} INFO - Started process (PID=16757) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:31:23.679+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:31:23.680+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:31:23.680+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:31:23.712+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:31:23.708+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:31:23.713+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:31:23.733+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.062 seconds
[2024-03-14T15:31:53.947+0000] {processor.py:161} INFO - Started process (PID=16812) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:31:53.948+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:31:53.949+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:31:53.949+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:31:53.980+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:31:53.976+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:31:53.980+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:31:53.995+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.052 seconds
[2024-03-14T15:32:25.012+0000] {processor.py:161} INFO - Started process (PID=16867) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:32:25.013+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:32:25.014+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:32:25.014+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:32:25.046+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:32:25.041+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:32:25.047+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:32:25.079+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.070 seconds
[2024-03-14T15:32:55.290+0000] {processor.py:161} INFO - Started process (PID=16923) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:32:55.291+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:32:55.292+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:32:55.292+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:32:55.335+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:32:55.330+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:32:55.337+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:32:55.360+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.073 seconds
[2024-03-14T15:33:25.621+0000] {processor.py:161} INFO - Started process (PID=16979) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:33:25.622+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:33:25.623+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:33:25.623+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:33:25.664+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:33:25.656+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:33:25.665+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:33:25.683+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.064 seconds
[2024-03-14T15:33:56.081+0000] {processor.py:161} INFO - Started process (PID=17034) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:33:56.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:33:56.082+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:33:56.082+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:33:56.117+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:33:56.113+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:33:56.118+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:33:56.134+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.056 seconds
[2024-03-14T15:34:26.505+0000] {processor.py:161} INFO - Started process (PID=17090) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:34:26.506+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:34:26.507+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:34:26.507+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:34:26.540+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:34:26.535+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:34:26.541+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:34:26.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.067 seconds
[2024-03-14T15:34:56.870+0000] {processor.py:161} INFO - Started process (PID=17145) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:34:56.871+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:34:56.872+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:34:56.872+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:34:56.903+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:34:56.900+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:34:56.904+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:34:56.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.055 seconds
[2024-03-14T15:35:27.428+0000] {processor.py:161} INFO - Started process (PID=17200) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:35:27.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:35:27.432+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:35:27.432+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:35:27.471+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:35:27.467+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:35:27.472+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:35:27.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.074 seconds
[2024-03-14T15:35:58.003+0000] {processor.py:161} INFO - Started process (PID=17255) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:35:58.006+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:35:58.008+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:35:58.007+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:35:58.053+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:35:58.048+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:35:58.054+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:35:58.078+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.081 seconds
[2024-03-14T15:36:28.480+0000] {processor.py:161} INFO - Started process (PID=17310) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:36:28.481+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:36:28.482+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:36:28.482+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:36:28.515+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:36:28.511+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:36:28.516+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:36:28.532+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.055 seconds
[2024-03-14T15:36:59.253+0000] {processor.py:161} INFO - Started process (PID=17366) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:36:59.254+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:36:59.256+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:36:59.256+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:36:59.311+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:36:59.306+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:36:59.312+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:36:59.335+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.084 seconds
[2024-03-14T15:37:29.904+0000] {processor.py:161} INFO - Started process (PID=17421) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:37:29.905+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:37:29.906+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:37:29.906+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:37:29.949+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:37:29.945+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:37:29.949+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:37:29.985+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.083 seconds
[2024-03-14T15:38:00.441+0000] {processor.py:161} INFO - Started process (PID=17476) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:38:00.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:38:00.444+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:38:00.444+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:38:00.482+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:38:00.478+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:38:00.483+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:38:00.510+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.072 seconds
[2024-03-14T15:38:31.135+0000] {processor.py:161} INFO - Started process (PID=17531) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:38:31.136+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:38:31.137+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:38:31.137+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:38:31.180+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:38:31.176+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:38:31.181+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:38:31.200+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.068 seconds
[2024-03-14T15:39:01.649+0000] {processor.py:161} INFO - Started process (PID=17587) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:39:01.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:39:01.652+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:39:01.651+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:39:01.693+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:39:01.687+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:39:01.694+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:39:01.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.067 seconds
[2024-03-14T15:39:31.768+0000] {processor.py:161} INFO - Started process (PID=17642) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:39:31.769+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:39:31.770+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:39:31.769+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:39:31.808+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:39:31.803+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:39:31.810+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:39:31.829+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.064 seconds
[2024-03-14T15:40:02.785+0000] {processor.py:161} INFO - Started process (PID=17698) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:40:02.785+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:40:02.786+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:40:02.786+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:40:02.828+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:40:02.824+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:40:02.829+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:40:02.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.073 seconds
[2024-03-14T15:40:33.558+0000] {processor.py:161} INFO - Started process (PID=17753) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:40:33.560+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:40:33.561+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:40:33.561+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:40:33.616+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:40:33.612+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:40:33.617+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:40:33.632+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.078 seconds
[2024-03-14T15:41:03.910+0000] {processor.py:161} INFO - Started process (PID=17808) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:41:03.911+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:41:03.912+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:41:03.912+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:41:03.953+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:41:03.948+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:41:03.954+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:41:03.982+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.076 seconds
[2024-03-14T15:41:34.063+0000] {processor.py:161} INFO - Started process (PID=17863) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:41:34.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:41:34.065+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:41:34.065+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:41:34.099+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:41:34.096+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:41:34.100+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:41:34.128+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.068 seconds
[2024-03-14T15:42:05.114+0000] {processor.py:161} INFO - Started process (PID=17919) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:42:05.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:42:05.117+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:42:05.116+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:42:05.158+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:42:05.152+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:42:05.159+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:42:05.181+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.070 seconds
[2024-03-14T15:42:35.681+0000] {processor.py:161} INFO - Started process (PID=17974) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:42:35.682+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:42:35.682+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:42:35.682+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:42:35.736+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:42:35.731+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:42:35.736+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:42:35.788+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.110 seconds
[2024-03-14T15:43:06.097+0000] {processor.py:161} INFO - Started process (PID=18029) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:43:06.098+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:43:06.100+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:43:06.099+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:43:06.137+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:43:06.132+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:43:06.138+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:43:06.165+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.071 seconds
[2024-03-14T15:43:36.834+0000] {processor.py:161} INFO - Started process (PID=18084) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:43:36.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:43:36.836+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:43:36.836+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:43:36.867+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:43:36.863+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:43:36.869+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:43:36.884+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.052 seconds
[2024-03-14T15:44:07.125+0000] {processor.py:161} INFO - Started process (PID=18139) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:44:07.126+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:44:07.127+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:44:07.127+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:44:07.159+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:44:07.155+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:44:07.159+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:44:07.175+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.053 seconds
[2024-03-14T15:44:37.303+0000] {processor.py:161} INFO - Started process (PID=18194) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:44:37.304+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:44:37.305+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:44:37.305+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:44:37.340+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:44:37.335+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:44:37.340+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:44:37.355+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.055 seconds
[2024-03-14T15:45:07.556+0000] {processor.py:161} INFO - Started process (PID=18249) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:45:07.558+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:45:07.560+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:45:07.559+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:45:07.595+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:45:07.591+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:45:07.596+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:45:07.615+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.062 seconds
[2024-03-14T15:45:37.763+0000] {processor.py:161} INFO - Started process (PID=18304) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:45:37.764+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:45:37.765+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:45:37.765+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:45:37.800+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:45:37.796+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:45:37.801+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:45:37.819+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.059 seconds
[2024-03-14T15:46:08.130+0000] {processor.py:161} INFO - Started process (PID=18359) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:46:08.131+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:46:08.132+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:46:08.131+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:46:08.178+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:46:08.174+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:46:08.179+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:46:08.197+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.070 seconds
[2024-03-14T15:46:38.363+0000] {processor.py:161} INFO - Started process (PID=18415) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:46:38.364+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:46:38.365+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:46:38.365+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:46:38.402+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:46:38.398+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:46:38.402+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:46:38.425+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.064 seconds
[2024-03-14T15:47:08.692+0000] {processor.py:161} INFO - Started process (PID=18471) to work on /opt/airflow/dags/create_dag.py
[2024-03-14T15:47:08.693+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/create_dag.py for tasks to queue
[2024-03-14T15:47:08.695+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:47:08.694+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag.py
[2024-03-14T15:47:08.741+0000] {logging_mixin.py:188} INFO - [2024-03-14T15:47:08.737+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/create_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag.py", line 105, in <module>
    bigquery_external_table_task = BigQueryCreateExternalTableOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1690, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 811, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'bigquery_external_table_task' has already been added to the DAG
[2024-03-14T15:47:08.742+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag.py
[2024-03-14T15:47:08.773+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/create_dag.py took 0.084 seconds
